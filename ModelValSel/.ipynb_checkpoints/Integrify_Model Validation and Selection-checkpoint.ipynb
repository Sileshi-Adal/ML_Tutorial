{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-97da75c1d52f0687",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Model Validation and Selection\n",
    "\n",
    "As we have seen in the previous rounds, machine learning (ML) methods combine particular choices for features, labels, hypothesis space (of predictor functions) and loss function (that measures the quality of a particular predictor function). See **Chapter 3** of the course book to see how many popular ML methods are obtained as particular combinations of some hypothesis space and some loss function. \n",
    "\n",
    "In principle, we can freely choose a hypothesis space (model) and loss function for a given ML problem. However, in practice we have to restrict the hypothesis space to a subset of predictor functions to cope with **limited  computational resources**. Since existing computing hard- and software is very efficient in implementing matrix operations, a popular choice for the hypothesis space is the subset of linear functions $h(\\mathbf{x})= \\mathbf{w}^{T} \\mathbf{x}$. Another important family of hypothesis spaces is obtained from decision trees. We have seen in Round 3 how sufficiently large decision trees allow to represent more complicated functions than linear functions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49483a7aad5aa158",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "\n",
    "In this exercise, you will learn a simple but powerful approach for choosing a \"good\" hypothesis space out of a set of alternatives. In particular, you will \n",
    "\n",
    "* learn that the training error is a poor quality measure for a hypothesis space \n",
    "* learn that the validation error is a more useful quality measure for a hypothesis space \n",
    "* learn how to choose between different hypothesis spaces (models) using the validation error\n",
    "* learn about regularization as a soft variant of model selection. \n",
    "\n",
    "## Relevant Sections in [Course Book](https://arxiv.org/abs/1805.05052)  \n",
    "\n",
    "Chapter 2; Chapter 6; Chapter 7\n",
    "\n",
    "## Background Material \n",
    "\n",
    "[Video lecture](https://www.youtube.com/watch?v=MyBSkmUeIEs) of Prof. Andrew Ng on model validation and selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-90c66bf37e8ad022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Consider a ML problem revolving around the prediction of a numeric quantity (label) $y \\in \\mathbb{R}$ based on some features $\\mathbf{x}=(x_{1},\\ldots,x_{n}) \\in \\mathbb{R}^{n}$ of a data point. At our disposal are some labeled data points which collect into the set $\\mathbb{X} = \\{ \\big( \\mathbf{x}^{(i)},y^{(i)}\\big)\\}$. Each data point is characterized by features $\\mathbf{x}^{(i)}$ and a label (quantity of interest) $y^{(i)}$. \n",
    "\n",
    "Assume we came up with some predictor $h(\\mathbf{x})$ which works extremely well on the dataset $\\mathbb{X}$,\n",
    "\\begin{equation}\n",
    "\\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}}\\big(y^{(i)} - \\underbrace{h(\\mathbf{x}^{(i)})}_{= \\hat{y}^{(i)}}\\big)^{2}\\approx 0.\n",
    "\\end{equation}\n",
    "\n",
    "Even if the predictor $h(\\mathbf{x})$ does exceptionally well on the data set $\\mathbb{X}$, we can not be sure that the method will work well on new data points (different from the data points in $\\mathbb{X}$). \n",
    "This is particularly true for ML methods that allow for highly complicated predictor functions $h(\\mathbf{x})$. Examples of highly complicated predictor functions are linear functions $h(\\mathbf{x}) = \\mathbf{w}^{T} \\mathbf{x} = \\sum_{r=1}^{n} x_{r} w_{r}$ using a large number of features $x_{1},\\ldots,x_{n}$ (the number $n$ of features is a measure of the complexity of the space of linear functions). It can be shown that if the number of features linear predictors on data points with $n$ features allows to perfectly fit any set of $m$ labels $y^{(i)}$ whenever $m \\leq n$. \n",
    "\n",
    "Another example for a vast hypothesis space is given by the set of all predictor functions that can be represented by a given deep neural network structure with billions of adjustable weights (each edge has one weight $w$ that can be tuned). When using an extremely large hypothesis space $\\mathcal{H}$, it is very likely that just by chance one finds a predictor function $h(\\cdot) \\in \\mathcal{H}$ that perfectly fits (reproduces) a given set of labeled data points (unless this dataset is VERY large). \n",
    "\n",
    "ML methods that perform well on training data due to memorization of the training data do not pick up any intrinsic relation between features $\\mathbf{x}$ and label $y$. Such a ML method merely overfits the training data and will not be able to **generalize well** to new data. \n",
    "\n",
    "In order to detect overfitting we need to implement some form of **validation**. The idea behind validation is quite simple: \n",
    "\n",
    "**Split the available labeled data points $\\mathbb{X}$ into two different subsets, a training set $\\mathbb{X}^{(t)}$ of size $m_{t}$ and a validation set $\\mathbb{X}^{(v)}$ of size $m_{v}$.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-714536d18e8f3dff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='splitTestandValidationfunction'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Demo.</b> Split Data into Training and Validation Set.\n",
    "\n",
    "The code snippet below creates a synthetic dataset of $m$ datapoints $(\\mathbf{x}^{(i)},y^{(i)}\\big)$. Each data point is characterized by the feature vector $\\mathbf{x}^{(i)}=\\big(x^{(i)}_{1},\\ldots,x_{n}^{(i)}\\big)^{T} \\in \\mathbb{R}^{n}$ and a numeric label $y^{(i)} \\in \\mathbb{R}$. The feature vectors are stored in the rows of the matrix $\\mathbf{X}\\in \\mathbb{R}^{m \\times n}$. The labels are collected into the vector $\\mathbf{y}=\\big(y^{(1)},\\ldots,y^{(m)}\\big)^{T} \\in \\mathbb{R}^{m}$. \n",
    "\n",
    "The Python library `scikit-learn` provides the function \n",
    "\n",
    "`X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=2)` \n",
    "\n",
    "which can be used to split a dataset into training and validation set. The function reads in the feature vectors in the numpy array `X` of shape ($m,n$) and the labels in the numpy array `y` of shape ($m,1$). \n",
    "\n",
    "The function returns numpy arrays `X_train` of shape ($m_{t},n$), `X_val`of shape ($m_{v},n$), `y_train` of shape ($m_{t},1$) and `y_val` of shape ($m_{v},1$). The input parameter `test_size` specifies the relative size $m_{v}/m$ of the validation set. When using `test_size=0.2`, $20 \\%$ of the original data points are used for the validation set and the and the remaining $80 \\%$ in the training set.\n",
    "\n",
    "[Python Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8b4f6fb62eef46b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderjung/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics\n",
    "\n",
    "m = 20 \n",
    "n = 10 \n",
    "\n",
    "X = np.random.randn(m,n)   # create feature vectors using random numbers\n",
    "y = np.random.randn(m,1)   # create labels using random numbers \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2) # 80% training and 20% test\n",
    "\n",
    "plt.rc('legend', fontsize=20) \n",
    "plt.rc('axes', labelsize=20) \n",
    "fig1, axes1 = plt.subplots(figsize=(15, 5))\n",
    "axes1.scatter(X[:, 0], X[:, 1], c='g', s=200,marker ='x', label='original dataset')\n",
    "axes1.legend(loc='best')\n",
    "axes1.set_xlabel('feature x1')\n",
    "axes1.set_ylabel('feature x2')\n",
    "\n",
    "fig2, axes2 = plt.subplots(figsize=(15, 5))\n",
    "axes2.scatter(X_train[:, 0], X_train[:, 1], c='g', s=200,marker ='o', label='training set')\n",
    "axes2.scatter(X_val[:, 0], X_val[:, 1], c='brown', s=200,marker ='s', label='validation set')\n",
    "axes2.legend(loc='best')\n",
    "axes2.set_xlabel('feature x1')\n",
    "axes2.set_ylabel('feature x2')\n",
    "\n",
    "\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d82c01565964839f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The training set $\\mathbb{X}^{(t)}$ is used to learn the optimal predictor $h_{\\rm opt} \\in \\mathcal{H}$ out of the hypothesis space: \n",
    "\\begin{equation} \n",
    "h_{\\rm opt}  = {\\rm argmin}_{h \\in \\mathcal{H}} \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - \\underbrace{h(\\mathbf{x}^{(i)})}_{= \\hat{y}^{(i)}}\\big)^{2}. \n",
    "\\end{equation} \n",
    "The minimum objective value of this optimization problem is the **training error** \n",
    "\\begin{equation}\n",
    "E_{\\rm train} = (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h_{\\rm opt}(\\mathbf{x}^{(i)})\\big)^{2}.\n",
    "\\end{equation} \n",
    "Note that the training error $E_{\\rm train}$ measures the performance of the predictor $h_{\\rm opt}$ on the same data points $\\mathbb{X}^{(t)}$ which have been used to tune (learn) $h_{\\rm opt}$. Therefore, the training error $E_{\\rm train}$ is too **optimistic** as an estimate for the average error (or loss) of $h_{\\rm opt}$ on new data points which are different from $\\mathbb{X}^{(t)}$. \n",
    "\n",
    "To estimate the error incurred by $h_{\\rm opt}$ on new data points, we calculate the average loss incurred by $h_{\\rm opt}$ on the validation set $\\mathbb{X}^{(v)}$. This yields the **validation error**\n",
    "\\begin{equation}\n",
    "E_{\\rm val} = (1/m_{v}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(v)}} \\big(y^{(i)} - h_{\\rm opt}(\\mathbf{x}^{(i)})\\big)^{2}. \n",
    "\\end{equation}\n",
    "The validation error $E_{\\rm val}$ is a much better estimate for the average error (or loss) of the predictor $h_{\\rm opt}$. \n",
    "\n",
    "The training error $E_{\\rm train}$ provides a quality measure for the particular predictor $h_{\\rm opt}$. In contrast, the validation error $E_{\\rm val}$ provides a quality measure for the entire hypothesis space $\\mathcal{H}$. Therefore, we can use the validation error for **model selection**. We choose the best hypothesis space $\\mathcal{H}$ out of a set of alternative hypothesis spaces $\\mathcal{H}^{(1)},\\mathcal{H}^{(2)},\\ldots$ according to the corresponding validation errors $E_{\\rm val}(1),E_{\\rm val}(2),\\ldots$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de358afd2c4fac99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Problem \n",
    "\n",
    "The concept of model validation and selection is best understood by working through a particular example. To this end, we revisit the problem of predicting the price of a house (or real estate object). In **Round 2 - Regression**, we have formalized house price prediction as a ML problem with \n",
    "\n",
    "1. **data points** which represent houses (or \"real estate objects\"). Each data point is characterized by features $\\mathbf{x} = (x_{1},\\ldots,x_{n}) \\in \\mathbb{R}^{n}$ such as number of rooms, etc. Moreover, we define the price of a house as the label $y$ of a data point. Note that the label $y \\in \\mathbb{R}$ is only known for previous house sales! \n",
    "\n",
    "2. a **hypothesis space** $\\mathcal{H}$ consisting of predictor functions $h: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ from features $\\mathbf{x} \\in \\mathbb{R}^{n}$ to a predicted price $\\hat{y}=h(\\mathbf{x})\\in \\mathbb{R}$ and \n",
    "\n",
    "3. a **loss function**, such as squared error loss, which measures the quality of a predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d2949507bb9fa14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='handsondata'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "<p><b>Demo.</b> Loading the Data.</p>\n",
    "    \n",
    "The following code snippet defines a function `X,y= GetFeaturesLabels(m,n)` which reads in data points representing previous house sales. Each of these data points is charactized by a feature vector $\\mathbf{x}^{(i)}$ and the label $y^{(i)}$.\n",
    "\n",
    "The input parameters of the function `GetFeaturesLabels(m,n)` are the number `m` of data points and the number `n` of features to be used for each data point. The function returns a matrix $\\mathbf{X}$ and vector $\\mathbf{y}$. \n",
    "\n",
    "The features $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{n}$ for the sold houses are stored in the rows of the feature matrix $\\mathbf{X} = \\begin{pmatrix} \\mathbf{x}^{(1)} & \\ldots & \\mathbf{x}^{(m)} \\end{pmatrix}^{T}$ which is represented by a numpy array `X` of shape (m,n). The corresponding selling prices are collected in the vector $\\mathbf{y}=\\big(y^{(1)},\\ldots,y^{(m)}\\big)^{T}$ represented by the numpy array `y` of shape (m,1). \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e47aca8cdac9893",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def GetFeaturesLabels(m=20, n=10):\n",
    "\n",
    "    house_dataset = load_boston()           # load some house sales data \n",
    "    house = pd.DataFrame(house_dataset.data, columns=house_dataset.feature_names) \n",
    "    x1 = house['RM'].values.reshape(-1,1)   # vector whose entries are the average room numbers for each sold houses\n",
    "    x2 = house['NOX'].values.reshape(-1,1)  # vector whose entries are the nitric oxides concentration for sold houses\n",
    "\n",
    "\n",
    "    x1 = x1[0:m]         # choose first feature of first m data points from the database \n",
    "    x2 = x2[0:m]         # choose second feature of first m data pionts from the database\n",
    "    np.random.seed( 15 )\n",
    "    X = np.hstack((x1,x2,np.random.randn(n,m).T)) # add some \"extra\" features, maybe it helps :-) \n",
    "    \n",
    "    X = X[:,0:n]      # some reshaping of the numpy arrays \n",
    "\n",
    "    y = house_dataset.target.reshape(-1,1)  # creates a vector whose entries are the labels for each sold house\n",
    "    y = y[0:m]       # chosse labels of first m data points in the database \n",
    "    \n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)          # normalize feature values to standard value range \n",
    "    scaler = StandardScaler().fit(y)\n",
    "    y = scaler.transform(y)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ddfcf8b06137c570",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear Predictors \n",
    "\n",
    "To predict the price $y$ of a house based on the first $r$ features (or characteristics) $\\mathbf{x}=(x_{1},\\ldots,x_{r})^{T} \\in \\mathbb{R}^{r}$, we try to find (or learn) a predictor function $h(\\mathbf{x})$ such that $y \\approx h(\\mathbf{x})$. We restrict ourselves to linear predictor functions. Thus, we use the hypothesis space \n",
    "$$ \\mathcal{H}^{(r)} = \\{ h(\\mathbf{x}) = \\mathbf{w}^{T} \\mathbf{x} \\mbox{ with some weight } \\mathbf{w}\\in \\mathbb{R}^{r} \\}.$$ \n",
    "Carefully note that for each value $r\\in \\{1,\\ldots,n\\}$, we obtain a different hypothesis space $\\mathcal{H}^{(r)}$. \n",
    "\n",
    "In order to find (learn) good choices for the weight vector $\\mathbf{w}$ we can minimize the average squared error loss on labeled data points in a training set $\\mathbb{X}^{(t)}$: \n",
    "\\begin{align}\\min_{h \\in \\mathcal{H}^{(r)}}  & \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}}  (y^{(i)} - h(\\mathbf{x}^{(i)}) )^{2} \\nonumber \\\\ \n",
    "= \\min_{\\mathbf{w} \\in \\mathbb{R}^{r}} & \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}}  \\big(y^{(i)} -  \\mathbf{w}^{T}\\mathbf{x}^{(i)}  \\big)^{2}.\n",
    "\\end{align}\n",
    "Solving this training problem provides us with optimal choices for weight vector $\\mathbf{w}$. \n",
    "However, we have another design parameter at our disposal: the number $r$ of features! While in our data base each house is characterized by $n$ features, we are free to use fewer e.g. only the first $r \\leq n$ of these features. \n",
    "\n",
    "What is the best choice for $r$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0399c961c185f2f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Wrong Way \n",
    "\n",
    "At first sight it might seem reasonable to try out each hypothesis space $\\mathcal{H}^{(r)}$ on the training data $\\mathbb{X}^{(t)}$. For each $r=1,\\ldots,h,$ we learn the optimal predictor $h_{\\rm opt}^{(r)} \\in \\mathcal{H}^{(r)}$ by minimizing the average loss on the training set: \n",
    "\\begin{align} \n",
    "h_{\\rm opt}^{(r)} & = {\\rm argmin}_{h \\in \\mathcal{H}^{(r)}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big( y^{(i)}- h(\\mathbf{x}^{(i)}) \\big)^{2}. \n",
    "\\end{align} \n",
    "The corresponding training error is     \n",
    "\\begin{align} \n",
    "E_{\\rm train}(r) & = (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big( y^{(i)}- h_{\\rm opt}^{(r)}(\\mathbf{x}^{(i)}) \\big)^{2} \\nonumber \\\\ \n",
    "& = \\min_{h \\in \\mathcal{H}^{(r)}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big( y^{(i)}- h(\\mathbf{x}^{(i)}) \\big)^{2} \\nonumber \\\\ \n",
    "& = \\min_{\\mathbf{w} \\in \\mathbb{R}^{r}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big( y^{(i)}- \\mathbf{w}^{T} \\mathbf{x}^{(i)}  \\big)^{2} \\nonumber \\\\ \n",
    "& = \\min_{\\mathbf{w} \\in \\mathbb{R}^{r}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big( y^{(i)}- \\sum_{s=1}^{r}w_{s} x_{s}^{(i)}  \\big)^{2} \n",
    "\\end{align} \n",
    "It is tempting to choose the number $r$ of features according to the smallest training error $E_{\\rm train}(r)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0aaf4cb2c4109eb2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<a id='trainModel'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <p><b>Demo.</b> Varying Number of Features </p>\n",
    "    \n",
    "The following code snippet computes the training error E(r) for each choice for the number r of features. For each particular value $r=1,\\ldots,n$, the best linear predictor $h(\\mathbf{x}) = \\mathbf{w}^{T} \\mathbf{x}$ is using the Python function `LinearRegression.fit()`\n",
    "\n",
    "[Documentation of Python function](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) \n",
    "\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acd5c9243afcd36f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "m = 20                        # we use the first m=20 data points from the house sales database \n",
    "n = 10                        # maximum number of features used \n",
    "\n",
    "X,y = GetFeaturesLabels(m,n)  # read in m data points using n features \n",
    "linreg_error = np.zeros(n)    # vector for storing the training error of LinearRegresion.fit() for each r\n",
    "\n",
    "for r_minus_1 in range(n):  # loop over number of features r (minus 1)\n",
    "    reg = LinearRegression(fit_intercept=False)   # create an object for linear predictors\n",
    "    reg = reg.fit(X[:,:(r_minus_1 + 1)], y)                 # find best linear predictor (minimize training error)\n",
    "    pred = reg.predict(X[:,:(r_minus_1 + 1)])               # compute predictions of best predictors \n",
    "    linreg_error[r_minus_1] = mean_squared_error(y, pred) # compute training error \n",
    "\n",
    "plot_x = np.linspace(1, n, n, endpoint=True)      # plot_x contains grid points for x-axis\n",
    "\n",
    "# Plot training error E(r) as a function of feature number r\n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.plot(plot_x, linreg_error, label='$E(r)$', color='red')\n",
    "plt.xlabel('# of features $r$')\n",
    "plt.ylabel('training error $E(r)$')\n",
    "plt.title('training error vs number of features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fba2c040fb160f3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Let's Interpret the Results!\n",
    "\n",
    "Based on the above plot, we could argue that we should choose the linear model with $r=10$ features, since this yields the lowest training error $E(r)$. **This reasoning is incorrect**, since our ultimate goal is to find a predictor for new data points (new real-estates). Our goal is not to reproduce accurately the prices of previous house sales! \n",
    "\n",
    "Using the training error $E_{\\rm train}(r)$ to assess the quality of the predictor $h_{\\rm opt}^{(r)}$ is misleading since $h_{\\rm opt}^{(r)}$ is based on the weight vector $\\mathbf{w}$ and intercept that is perfectly tuned to the training data $\\mathbb{X}^{(t)}$. Also, the more features (larger $r$) we use, the better we will be able to fit the training data $\\mathbb{X}^{(t)}$ (obtain smaller training error). However, this does not necessarily lead to better performance on new data. A complex model with too many features (large $r$) might only fit the training data very well, and generalize poorly to new data.\n",
    "\n",
    "Consider the case of $r=m_{\\rm train}$, i.e., the number of features is the same as the number of labeled data points in the training set. Under very mild conditions it can be shown that in this case there always exists a linear predictor $h(\\mathbf{x})=\\mathbf{w}^{T} \\mathbf{x}$ such that $y^{(i)} = h(\\mathbf{x}^{(i)})$, i.e., the training error is exactly zero (see Chapter 7.1 of the course book)! \n",
    "A better way to evaluate the quality of a predictor is presented next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e508ee65304e99f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  The Right Way\n",
    "\n",
    "The training error $E_{\\rm train}(r)$ is a bad measure for the quality of a hypothesis space $\\mathcal{H}^{(r)}$ since it will always favor larger spaces (larger number $r$ of features). A more useful measure for the quality of a hypothesis space $\\mathcal{H}^{(r)}$ is the validation error \n",
    "\\begin{equation}\n",
    "E_{\\rm val}(r) = (1/m_{v}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(v)}} \\big(y^{(i)} - h^{(r)}_{\\rm opt}(\\mathbf{x}^{(i)})\\big)^{2}. \n",
    "\\end{equation} \n",
    "Here, the predictor $h_{\\rm opt}$ is obtained by minimizing the training error over all linear predictors using $r$ features: \n",
    "\\begin{equation}\n",
    " h^{(r)}_{\\rm opt} = {\\rm argmin}_{h \\in \\mathcal{H}^{(r)}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h(\\mathbf{x}^{(i)})\\big)^{2}.\n",
    "\\end{equation}\n",
    "Since each predictor function $h \\in \\mathcal{H}^{(r)}$ is given by $h(\\mathbf{x}) = \\mathbf{w}^{T} \\mathbf{x}$ we can find the optimal predictor via the optimum weight and intercept \n",
    "\\begin{equation}\n",
    "\\mathbf{w}_{\\rm opt} = {\\rm argmin}_{\\mathbf{w}\\in \\mathbb{R}^{r}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - \\mathbf{w}^{T} \\mathbf{x}^{(i)} \\big)^{2}. \n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a7b319a106cbd05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='splitTestandValidationfunction'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Demo.</b> Generate Training and Validation Set.\n",
    "   \n",
    "We use the `scikit-learn` library function `train_test_split()` to split the data points obtained from the function `GetFeaturesLabels` into a training and validation (or test) set. We use the function with argument `test_size=0.2`, which means 20 percent of data points are test set and the remaining 80 percent as training set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9cc67382efb4ce19",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "m = 20                        # we use the first m=20 data points from the house sales database \n",
    "n = 10                        # maximum number of features used \n",
    "\n",
    "X,y = GetFeaturesLabels(m,n)  # read in m data points using n features \n",
    "\n",
    "# Compute the training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-428dadef568d5aef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='trainValErrorsfunction'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Demo.</b> Compute Training and Validation Error. \n",
    "\n",
    "The code snippet below computes the training error and validation error for each choice of number $r=1,\\ldots,n$. of features. The training errors are stored in a numpy array `err_train` of shape (n,1) and the validation errors are stored in the numpy array `err_val` of shape (n,1). The first entries of `err_train` and `err_val` should be $E_{\\rm train}(1)$ and $E_{\\rm val}(1)$. \n",
    "\n",
    "The optimum number $r$ of features (such that the validation error is smallest) is stored in the variable `best_model`. \n",
    "\n",
    "Hint: you can determine the index of the smallest entry in a numpy array using `np.argmin()` [see documentation](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.argmin.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7791084dee96529b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "err_train = np.zeros([n,1]) \n",
    "err_val = np.zeros([n,1])\n",
    "    \n",
    "\n",
    "for r_minus_1 in range(n):\n",
    "    lin_reg = LinearRegression(fit_intercept=False)\n",
    "    lin_reg = lin_reg.fit(X_train[:,:(r_minus_1+1)], y_train)\n",
    "    w_opt = lin_reg.coef_\n",
    "    y_pred_train = lin_reg.predict(X_train[:,:(r_minus_1+1)])\n",
    "    err_train[r_minus_1] = mean_squared_error(y_train, y_pred_train)\n",
    "    y_pred_val = lin_reg.predict(X_val[:,:(r_minus_1+1)])\n",
    "    err_val[r_minus_1] = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "\n",
    "\n",
    "best_model = np.argmin(err_val)+1\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64473b41dbc92dfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36765195]\n",
      " [0.21796853]\n",
      " [0.41507308]\n",
      " [0.44818207]]\n"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation errors for the different number of features r\n",
    "\n",
    "plt.plot(range(1, n + 1), err_train, color='black', label=r'$E_{\\rm train}(r)$', marker='o')\n",
    "plt.plot(range(1, n + 1), err_val, color='red', label=r'$E_{\\rm val}(r)$', marker='x')\n",
    "\n",
    "plt.title('Training and validation error for different number of features')\n",
    "plt.ylabel('Empirical error')\n",
    "plt.xlabel('r features')\n",
    "plt.xticks(range(1, n + 1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(err_val[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a417d9495eb3f40e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## K-fold Cross-Validation\n",
    "\n",
    "In general, there is no unique optimal way of splitting a data set into training and validation set. The precise choice of how to divide data points into training and validation set and also their relative size (80/20, 50/50 ...) has to be considered case-by-case for the application at hand. \n",
    "\n",
    "To get more guidance on how to split the data, one typically needs to have additional knowledge about the statistical properties of the data generating process. Given an accurate probabilistic model for the data points, allows determining optimal split ratios between training and validation set. Probabilistic (generative) models for the observed data points is beyond the scope of this course. \n",
    "\n",
    "Using only a single split of the data into training and validation set bears the risk of being extremely \"unlucky\". The single split might result in a highly non-typical validation set such that the validation error is not reliable as a measure for the average loss on new data. $K$-fold cross-validation is a straightforward extension of the \"single-split approach\" making it more robust. \n",
    "\n",
    "$K$-fold cross-validation randomly splits the data into $K$ equal-sized subsets (\"folds\"). It then executes $K$ rounds, each round corresponding to one of the $K$ folds. In the $k$th round, the $k$th fold is used as validation set and the remaining $K-1$ folds are used as training set. The validation errors obtained during each fold are then averaged to obtain the final validation error. \n",
    "\n",
    "As an example, the diagram of a 5-fold cross-validation is depicted below. For each round, the fold which is used as validation set is indicated by \"test\". \n",
    "\n",
    "![Components](cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-13d40bbc019a9337",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='kfold'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <p><b>Demo.</b> K-Fold Cross Validation.</p>\n",
    "    \n",
    "The code snippet below peforms K-fold cross validation with $K=5$ for linear predictors using $r=2$ features. \n",
    "\n",
    "</div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb92bc591606de2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error (averaged over 5 folds):  0.27420727178433746\n",
      "Validation error (averaged over 5 folds): 0.38344721339219784\n"
     ]
    }
   ],
   "source": [
    "# Import KFold class from scikitlearn library\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "K=5    # number of folds/rounds/splits\n",
    "kf = KFold(n_splits=K, shuffle=False)\n",
    "kf = kf.split(X)\n",
    "kf = list(kf)                 # kf is a list representing the rounds of k-fold CV\n",
    "\n",
    "m = 20                        # we use the first m=20 data points from the house sales database \n",
    "n = 10                        # maximum number of features used \n",
    "\n",
    "X,y = GetFeaturesLabels(m,n)  # read in m data points with n features \n",
    "r=2    # we use only first two features for linear predictors h(x) = w^{T}x\n",
    "\n",
    "\n",
    "\n",
    "train_errors_per_cv_iteration = []\n",
    "test_errors_per_cv_iteration = []  \n",
    "\n",
    "# for loop over K rounds \n",
    "        \n",
    "for train_indices, test_indices in kf:\n",
    "        \n",
    "    reg = LinearRegression(fit_intercept=False)\n",
    "    reg = reg.fit(X[train_indices,:(r+1)], y[train_indices])\n",
    "    y_pred_train = reg.predict(X[train_indices,:(r+1)])\n",
    "    train_errors_per_cv_iteration.append(mean_squared_error(y[train_indices], y_pred_train))\n",
    "    y_pred_val = reg.predict(X[test_indices,:(r+1)])\n",
    "    test_errors_per_cv_iteration.append(mean_squared_error(y[test_indices], y_pred_val))\n",
    "            \n",
    "\n",
    "err_train= np.mean(train_errors_per_cv_iteration) # compute the mean of round-wise training errors\n",
    "err_val = np.mean(test_errors_per_cv_iteration)   # compute the mean of round-wise validation errors\n",
    "        \n",
    "print(\"Training error (averaged over 5 folds): \",err_train)\n",
    "print(\"Validation error (averaged over 5 folds):\", err_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a451b1c380ed82da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Regularization\n",
    "\n",
    "In what follows, we stick to the hypothesis space $\\mathcal{H}^{(n)}$ of linear predictors $h(\\mathbf{x}) = \\mathbf{w}^{T} \\mathbf{x}$ using the maximum number $n$ of features. To find a good predictor function we could try to mininize the training error $E_{\\rm train}$ over some training set $\\mathbb{X}^{(t)}$. However, as discussed above, for large $n$ (i.e., if we have collected a large amount of features for a house) we will easily find a predictor function $h(\\mathbf{x})=\\mathbf{w}^{T} \\mathbf{x}$ such that $E_{\\rm train}$ is small but the predictor function will do poorly on data points different from $\\mathbb{X}^{(t)}$. \n",
    "\n",
    "The idea of regularization is to somehow estimate (or approximate) the increase of the prediction error in new data which is different from the training set. This estimated (or anticipated) increase is represented by adding a **regularization term** to the training error: \n",
    "\\begin{equation}\n",
    "h^{(\\lambda)}_{\\rm opt}  = {\\rm argmin}_{h \\in \\mathcal{H}} \\underbrace{(1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h(\\mathbf{x}^{(i)}) \\big)^{2}}_{\\mbox{ training error}} + \\underbrace{\\alpha \\mathcal{R}(h)}_{\\mbox{anticipated increase of error (loss) on new data}}.  \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The regularization term $\\mathcal{R}(h)$ quantifies the anticipated increase in the validation error (compared to the training error) due to the \"complexity\" (e.g. the number of features used in a linear predictor) of a particular predictor. In a nutshell, the regularization term penalizes the use of more complex predictors and therefore favors \"simpler\" predictor functions. The precise meaning of \"complexity\" or \"simpler\" is determined by the (design) choice for the regularization term $\\mathcal{R}(h)$. \n",
    "\n",
    "Two widely used choices for measuring the complexity of linear predictors $h(\\mathbf{x}) = \\mathbf{w}^{T}\\mathbf{x}$ is the squared Euclidean norm $\\mathcal{R}(h) = \\|\\mathbf{w}\\|^{2}_{2}=\\sum_{r=1}^{n} w_{r}^{2}$ or the $\\ell_{1}$ norm $\\mathcal{R}(h) = \\|\\mathbf{w}\\|_{1}=\\sum_{r=1}^{n} |w_{r}|$. \n",
    "\n",
    "The regularization parameter $\\alpha$ offers a trade off between the prediction error (training error) incurred on the training data and the complexity of a predictor. The larger we choose $\\alpha$, the more emphasis is put on obtaining \"simple\" predictor functions. Using very small values for $\\alpha$ prefers predictor functions which achieve a small training error (at the expense of being a more complicated function). \n",
    "\n",
    "In order to actually implement regularization, we need to \n",
    "- choose (define) the function $\\mathcal{R}(h)$ that quantifies some notion of complexity of a predictor function $h \\in \\mathcal{H}^{(n)}$. \n",
    "- choose the value of the regularization parameter $\\lambda$. \n",
    "\n",
    "These two design choices can be based on validation. More precisely, \n",
    "- we propose a set of different choices for the function $\\mathcal{R}(h)$ and regularization parameter $\\alpha$, \n",
    "- for each choice for $\\alpha$ and $\\mathcal{R}(h)$, we learn a predictor that minimizes the regularized training error \n",
    "\n",
    "\\begin{equation}\n",
    "h^{(\\alpha)}_{\\rm opt}  = {\\rm argmin}_{h \\in \\mathcal{H}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h(\\mathbf{x}^{(i)}) \\big)^{2} + \\alpha \\mathcal{R}(h).    \n",
    "\\end{equation}\n",
    "- evaluate the resulting predictor $h^{(\\alpha)}_{\\rm opt}$ by computing the validation error\n",
    "\\begin{equation}\n",
    "E_{\\rm val}^{(\\alpha)} = (1/m_{\\rm v}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(v)}} \\big(y^{(i)} - h^{(\\alpha)}_{\\rm opt}(\\mathbf{x}^{(i)})\\big)^{2}.\n",
    "\\end{equation} \n",
    "\n",
    "We then use the regularization measure $\\mathcal{R}(h)$ and the value for $\\alpha$ with smallest validation error $E_{\\rm val}^{(\\alpha)}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a697f48e6cf7e933",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='ridgeReg'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <p><b>Demo.</b> Ridge Regression. </p>\n",
    "\n",
    "Ridge regression is obtained by linear regression, using linear predictor functions $h^{(\\mathbf{w})}(\\mathbf{x}) =\\mathbf{w}^{T} \\mathbf{x}$, with the regularization term $\\mathcal{R}(h)=\\|\\mathbf{w}\\|_{2}^{2}$. The optimal weight vector $\\mathbf{w}_{\\rm opt}$ can be found using the Python function `Ridge.fit()`. \n",
    "\n",
    "[see documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef05953e6a07a985",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weights: \n",
      " [[ 0.24110883 -0.22076067 -0.12888964  0.02009444 -0.04235676 -0.01655399\n",
      "  -0.03795704 -0.00459253 -0.01375981 -0.02381325]]\n",
      "Training error: \n",
      " 0.3694434471547521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "alpha_scaled = 2*n \n",
    "\n",
    "ridge = Ridge(alpha=alpha_scaled, fit_intercept=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_train)\n",
    "w_opt = ridge.coef_\n",
    "err_train = mean_squared_error(y_pred, y_train)\n",
    "\n",
    "# Print optimal weights and training error\n",
    "print('Optimal weights: \\n', w_opt)\n",
    "print('Training error: \\n', err_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b63b8bd46646688d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='lassoReg'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Demo.</b> Lasso Regression.\n",
    "\n",
    "The Lasso estimator is obtained by regularizing the training error of linear predictors $h(\\mathbf{x}) = \\mathbf{w}^{T} \\mathbf{x}$ with the complexity measure $\\mathcal{R}(h)= \\|\\mathbf{w}\\|_{1}$. The code snippet below uses the Python function `Lasso.fit()` to compute, using the Lasso regularization, the optimal predictor for $\\alpha=1$. \n",
    "\n",
    "Note that the Python function uses a different scaling of the training error ($1/(2m_{t})$ instead of $1/m_{t}$). Make sure you transform the value $\\alpha$ so that the Python function solves the regularized problem  \n",
    "\\begin{equation}\n",
    "h^{(\\alpha)}_{\\rm opt}  = {\\rm argmin}_{h \\in \\mathcal{H}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h(\\mathbf{x}^{(i)}) \\big)^{2} + \\alpha \\mathcal{R}(h).    \n",
    "\\end{equation}\n",
    "\n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6cd24ae92c6b545",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weights: \n",
      " [ 0.10085404 -0.13397314 -0.         -0.         -0.         -0.\n",
      "  0.         -0.         -0.         -0.        ]\n",
      "Training error: \n",
      " 0.64205177534816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "X,y = GetFeaturesLabels(m,n)  # read in m data points using n features \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2) # 80% training and 20% test\n",
    "alpha_val = 1\n",
    "\n",
    "lasso = Lasso(alpha=alpha_val/2, fit_intercept=False)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_train)\n",
    "w_opt = lasso.coef_\n",
    "training_error = mean_squared_error(y_pred, y_train)\n",
    "\n",
    "# Print optimal weights and the corresponding training error\n",
    "print('Optimal weights: \\n', w_opt)\n",
    "print('Training error: \\n', training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1355f27ba4fd6ca5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When using Lasso or ridge regression, we need to find a suitable value for the regularization parameter $\\alpha$. A simple but useful approach is **grid search**: We first specify a list of values to be used for the regularization parameter. For each value $\\alpha$, we determine a predictor $h^{(\\alpha)}$ by minimizing the regularized training error: \n",
    "\\begin{equation}\n",
    "h^{(\\alpha)}  = {\\rm argmin}_{h \\in \\mathcal{H}} (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h(\\mathbf{x}^{(i)}) \\big)^{2} + \\alpha \\mathcal{R}(h).    \n",
    "\\end{equation}\n",
    "The resulting training error is \n",
    "\\begin{equation} \n",
    "E_{\\rm train}(\\alpha) = (1/m_{t}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(t)}} \\big(y^{(i)} - h^{(\\alpha)}(\\mathbf{x}^{(i)}) \\big)^{2}. \n",
    "\\end{equation}\n",
    "Note that the training error $E_{\\rm train}(\\alpha)$ is measured on the training data $\\mathbb{X}^{t}$ which was also used to tune the predictor $h^{(\\alpha)}$ (in the above opimtization problem). Therefore, $E_{\\rm train}(\\alpha)$ is too optimistic as a measure for the average error of $h^{(\\alpha)}$ on new data points. Instead, we will measure the quality of $h^{(\\alpha)}$ via the validation error  \n",
    "\\begin{equation} \n",
    "E_{\\rm val}(\\alpha) = (1/m_{v}) \\sum_{\\big(\\mathbf{x}^{(i)},y^{(i)}\\big) \\in \\mathbb{X}^{(v)}} \\big(y^{(i)} - h^{(\\alpha)}(\\mathbf{x}^{(i)}) \\big)^{2} \n",
    "\\end{equation}\n",
    "incurred by the predictor $h^{(\\alpha)}$ on the validation set $\\mathbb{X}^{(v)}$. We then choose the value $\\alpha$ resulting in the smallest validation error $E_{\\rm val}(\\alpha)$. This grid search can be computationally expensive since we have to solve a separate optimization problem (of minimizing the regularized training error) for each value of $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e4d019532f4bff3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='lassoParameter'></a>\n",
    "<div class=\" alert alert-info\">\n",
    "    <b>Demo.</b> Tuning Lasso Parameter.\n",
    "    \n",
    "The code snippet below computes the Lasso estimator $h^{(\\alpha)}$ for each value $\\alpha$ from the list $\\alpha^{(1)},\\ldots,\\alpha^{(9)}$ stored in the numpy array `alpha_values`. The resulting validation errors $E_{\\rm val}(\\alpha^{(i)})$ and training errors $E_{\\rm train}(\\alpha^{(i)})$ are stored in the numpy array `err_val` of shape (9,1) and `err_train` of shape (9,1). The first entry `err_val[0]` should be $E_{\\rm val}(\\alpha^{(1)})$, and so on. For the optimal choice $\\alpha^{(i)}$ (yielding smallest validation error), the weight vector of the optimal predictor is stored in the numpy array `w_opt` of shape (n,1). \n",
    "\n",
    "[scikit-learn function for Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) \n",
    "\n",
    "Hint: Note that the input parameter `alpha` of the Python function `Lasso.fit()` is $\\alpha/2$ with $\\alpha$ being the regularization parameter in the optimization problem above.   \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef618671a3220a4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Specify a list of values for lambda to be considered\n",
    "alpha_values = np.array([0.0001, 0.001, 0.01, 0.05, 0.2, 1, 3, 10, 10e3])\n",
    "nr_values = len(alpha_values)\n",
    "err_val = np.zeros([nr_values,1])\n",
    "err_train = np.zeros([nr_values,1])\n",
    "\n",
    "for l in range(nr_values):\n",
    "    lasso = Lasso(alpha=alpha_values[l]/2, fit_intercept=False)\n",
    "    lasso = lasso.fit(X_train, y_train)\n",
    "    y_train_pred = lasso.predict(X_train)\n",
    "    err_train[l] = mean_squared_error(y_train_pred, y_train)\n",
    "    y_val_pred = lasso.predict(X_val)\n",
    "    err_val[l]=mean_squared_error(y_val_pred, y_val)\n",
    "    \n",
    "best_alpha_idx=np.argmin(err_val)\n",
    "lasso = Lasso(alpha=alpha_values[best_alpha_idx]/2, fit_intercept=False)\n",
    "lasso = lasso.fit(X_train, y_train)\n",
    "w_opt = lasso.coef_\n",
    "w_opt = w_opt.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-535f1b0a4667461c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the training and validation errors\n",
    "plt.plot(alpha_values, err_train, marker='o', label='training error')\n",
    "plt.plot(alpha_values, err_val, marker='o', label='validation error')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel(r'$E(\\alpha)$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
